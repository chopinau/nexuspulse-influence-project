#!/usr/bin/env python
"""
Report Engine å‘½ä»¤è¡Œç‰ˆæœ¬

è¿™æ˜¯ä¸€ä¸ªä¸éœ€è¦å‰ç«¯çš„å‘½ä»¤è¡ŒæŠ¥å‘Šç”Ÿæˆç¨‹åºã€‚
ä¸»è¦æµç¨‹ï¼š
1. æ£€æŸ¥PDFä¾èµ–
2. è·å–æœ€æ–°çš„logã€mdæ–‡ä»¶
3. ç›´æ¥è°ƒç”¨Report Engineç”ŸæˆæŠ¥å‘Šï¼ˆè·³è¿‡æ–‡ä»¶å¢åŠ å®¡æ ¸ï¼‰
4. è‡ªåŠ¨ä¿å­˜HTMLã€PDFï¼ˆå¦‚æœæœ‰ä¾èµ–ï¼‰å’ŒMarkdownåˆ°final_reports/ï¼ˆMarkdown ä¼šåœ¨ PDF ä¹‹åç”Ÿæˆï¼‰
5. [æ–°å¢] è‡ªåŠ¨å°†æŠ¥å‘Šå­˜å…¥ Supabase æ•°æ®åº“

ä½¿ç”¨æ–¹æ³•ï¼š
    python report_engine_only.py [é€‰é¡¹]

é€‰é¡¹ï¼š
    --query QUERY     æŒ‡å®šæŠ¥å‘Šä¸»é¢˜ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»æ–‡ä»¶åæå–ï¼‰
    --skip-pdf        è·³è¿‡PDFç”Ÿæˆï¼ˆå³ä½¿æœ‰ä¾èµ–ï¼‰
    --skip-markdown   è·³è¿‡Markdownç”Ÿæˆ
    --verbose         æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
    --auto            è‡ªåŠ¨ç¡®è®¤æ‰€æœ‰æç¤ºï¼ˆé€‚ç”¨äºæ— äººå€¼å®ˆè¿è¡Œï¼‰
    --help            æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
"""

import os
import sys

# ä¿®å¤è·¯å¾„ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°åŒç›®å½•ä¸‹çš„æ¨¡å— (è§£å†³ No module named 'utils' ç­‰é—®é¢˜)
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import json
import requests
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

from loguru import logger
# å°è¯•å¯¼å…¥ Supabaseï¼Œå¦‚æœå¤±è´¥åˆ™åœ¨è¿è¡Œæ—¶æŠ¥é”™
try:
    from supabase import create_client, Client
except ImportError:
    logger.warning("æœªå®‰è£… supabase åº“ï¼Œæ•°æ®åº“å­˜å‚¨åŠŸèƒ½å°†ä¸å¯ç”¨")

from config import settings as global_settings, Settings

# å…¨å±€é…ç½®
VERBOSE = False

# é…ç½®æ—¥å¿—
def setup_logger(verbose: bool = False):
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    global VERBOSE
    VERBOSE = verbose

    logger.remove()  # ç§»é™¤é»˜è®¤å¤„ç†å™¨
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>",
        level="DEBUG" if verbose else "INFO"
    )


def check_dependencies() -> tuple[bool, Optional[str]]:
    """
    æ£€æŸ¥PDFç”Ÿæˆæ‰€éœ€çš„ç³»ç»Ÿä¾èµ–

    Returns:
        tuple: (is_available: bool, message: str)
            - is_available: PDFåŠŸèƒ½æ˜¯å¦å¯ç”¨
            - message: ä¾èµ–æ£€æŸ¥ç»“æœæ¶ˆæ¯
    """
    logger.info("=" * 70)
    logger.info("æ­¥éª¤ 1/5: æ£€æŸ¥ç³»ç»Ÿä¾èµ–")
    logger.info("=" * 70)

    try:
        from ReportEngine.utils.dependency_check import check_pango_available
        is_available, message = check_pango_available()

        if is_available:
            logger.success("âœ“ PDF ä¾èµ–æ£€æµ‹é€šè¿‡ï¼Œå°†åŒæ—¶ç”Ÿæˆ HTML å’Œ PDF æ–‡ä»¶")
        else:
            logger.warning("âš  PDF ä¾èµ–ç¼ºå¤±ï¼Œä»…ç”Ÿæˆ HTML æ–‡ä»¶")
            logger.info("\n" + message)

        return is_available, message
    except Exception as e:
        logger.error(f"ä¾èµ–æ£€æŸ¥å¤±è´¥: {e}")
        return False, str(e)


def get_latest_engine_reports() -> Dict[str, str]:
    """
    è·å–ä¸‰ä¸ªå¼•æ“ç›®å½•ä¸­çš„æœ€æ–°æŠ¥å‘Šæ–‡ä»¶

    Returns:
        Dict[str, str]: å¼•æ“åç§°åˆ°æ–‡ä»¶è·¯å¾„çš„æ˜ å°„
    """
    logger.info("\n" + "=" * 70)
    logger.info("æ­¥éª¤ 2/5: è·å–æœ€æ–°çš„åˆ†æå¼•æ“æŠ¥å‘Š")
    logger.info("=" * 70)

    # å®šä¹‰ä¸‰ä¸ªå¼•æ“çš„ç›®å½•
    directories = {
        "insight": "insight_engine_streamlit_reports",
        "media": "media_engine_streamlit_reports",
        "query": "query_engine_streamlit_reports"
    }

    latest_files = {}

    for engine, directory in directories.items():
        if not os.path.exists(directory):
            logger.warning(f"âš  {engine.capitalize()} Engine ç›®å½•ä¸å­˜åœ¨: {directory}")
            continue

        # è·å–æ‰€æœ‰ .md æ–‡ä»¶
        md_files = [f for f in os.listdir(directory) if f.endswith(".md")]

        if not md_files:
            logger.warning(f"âš  {engine.capitalize()} Engine ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ° .md æ–‡ä»¶")
            continue

        # è·å–æœ€æ–°æ–‡ä»¶
        latest_file = max(
            md_files,
            key=lambda x: os.path.getmtime(os.path.join(directory, x))
        )
        latest_path = os.path.join(directory, latest_file)
        latest_files[engine] = latest_path

        logger.info(f"âœ“ æ‰¾åˆ° {engine.capitalize()} Engine æœ€æ–°æŠ¥å‘Š")

    if not latest_files:
        logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•å¼•æ“æŠ¥å‘Šæ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œåˆ†æå¼•æ“ç”ŸæˆæŠ¥å‘Š")
        sys.exit(1)

    logger.info(f"\nå…±æ‰¾åˆ° {len(latest_files)} ä¸ªå¼•æ“çš„æœ€æ–°æŠ¥å‘Š")

    return latest_files


def confirm_file_selection(latest_files: Dict[str, str], auto_confirm: bool = False) -> bool:
    """
    å‘ç”¨æˆ·ç¡®è®¤é€‰æ‹©çš„æ–‡ä»¶æ˜¯å¦æ­£ç¡®

    Args:
        latest_files: å¼•æ“åç§°åˆ°æ–‡ä»¶è·¯å¾„çš„æ˜ å°„
        auto_confirm: æ˜¯å¦è‡ªåŠ¨ç¡®è®¤

    Returns:
        bool: ç”¨æˆ·ç¡®è®¤åˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    logger.info("\n" + "=" * 70)
    logger.info("è¯·ç¡®è®¤ä»¥ä¸‹é€‰æ‹©çš„æ–‡ä»¶ï¼š")
    logger.info("=" * 70)

    for engine, file_path in latest_files.items():
        filename = os.path.basename(file_path)
        # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
        mtime = os.path.getmtime(file_path)
        mtime_str = datetime.fromtimestamp(mtime).strftime("%Y-%m-%d %H:%M:%S")

        logger.info(f"  {engine.capitalize()} Engine:")
        logger.info(f"    æ–‡ä»¶å: {filename}")
        logger.info(f"    è·¯å¾„: {file_path}")
        logger.info(f"    ä¿®æ”¹æ—¶é—´: {mtime_str}")
        logger.info("")

    logger.info("=" * 70)

    if auto_confirm:
        logger.info(">> è‡ªåŠ¨æ¨¡å¼: å·²è‡ªåŠ¨ç¡®è®¤æ–‡ä»¶é€‰æ‹©")
        return True

    # æç¤ºç”¨æˆ·ç¡®è®¤
    try:
        response = input("æ˜¯å¦ä½¿ç”¨ä»¥ä¸Šæ–‡ä»¶ç”ŸæˆæŠ¥å‘Š? [Y/n]: ").strip().lower()

        # é»˜è®¤æ˜¯yï¼Œæ‰€ä»¥ç©ºè¾“å…¥æˆ–yéƒ½è¡¨ç¤ºç¡®è®¤
        if response == "" or response == "y" or response == "yes":
            logger.success("âœ“ ç”¨æˆ·ç¡®è®¤ï¼Œç»§ç»­ç”ŸæˆæŠ¥å‘Š")
            return True
        else:
            logger.warning("âœ— ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return False
    except (KeyboardInterrupt, EOFError):
        logger.warning("\nâœ— ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return False


def load_engine_reports(latest_files: Dict[str, str]) -> list[str]:
    """
    åŠ è½½å¼•æ“æŠ¥å‘Šå†…å®¹

    Args:
        latest_files: å¼•æ“åç§°åˆ°æ–‡ä»¶è·¯å¾„çš„æ˜ å°„

    Returns:
        list[str]: æŠ¥å‘Šå†…å®¹åˆ—è¡¨
    """
    reports = []

    for engine, file_path in latest_files.items():
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                reports.append(content)
                logger.debug(f"å·²åŠ è½½ {engine} æŠ¥å‘Šï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
        except Exception as e:
            logger.error(f"åŠ è½½ {engine} æŠ¥å‘Šå¤±è´¥: {e}")

    return reports


def extract_query_from_reports(latest_files: Dict[str, str]) -> str:
    """
    ä»æŠ¥å‘Šæ–‡ä»¶åä¸­æå–æŸ¥è¯¢ä¸»é¢˜

    Args:
        latest_files: å¼•æ“åç§°åˆ°æ–‡ä»¶è·¯å¾„çš„æ˜ å°„

    Returns:
        str: æå–çš„æŸ¥è¯¢ä¸»é¢˜
    """
    # å°è¯•ä»æ–‡ä»¶åä¸­æå–ä¸»é¢˜
    for engine, file_path in latest_files.items():
        filename = os.path.basename(file_path)
        # å‡è®¾æ–‡ä»¶åæ ¼å¼ä¸º: report_ä¸»é¢˜_æ—¶é—´æˆ³.md
        if "_" in filename:
            parts = filename.replace(".md", "").split("_")
            if len(parts) >= 2:
                # æå–ä¸­é—´éƒ¨åˆ†ä½œä¸ºä¸»é¢˜
                topic = "_".join(parts[1:-1]) if len(parts) > 2 else parts[1]
                if topic:
                    return topic

    # å¦‚æœæ— æ³•æå–ï¼Œè¿”å›é»˜è®¤å€¼
    return "ç»¼åˆåˆ†ææŠ¥å‘Š"


def generate_report(
    reports: list[str],
    query: str,
    pdf_available: bool,
    agent_config: Optional[Settings] = None
) -> Dict[str, Any]:
    """
    è°ƒç”¨Report Engineç”ŸæˆæŠ¥å‘Š

    Args:
        reports: æŠ¥å‘Šå†…å®¹åˆ—è¡¨
        query: æŠ¥å‘Šä¸»é¢˜
        pdf_available: PDFåŠŸèƒ½æ˜¯å¦å¯ç”¨
        agent_config: ReportAgent é…ç½®ï¼ˆå‘½ä»¤è¡Œå¯è¦†ç›– .envï¼‰

    Returns:
        Dict[str, Any]: åŒ…å«ç”Ÿæˆç»“æœçš„å­—å…¸
    """
    logger.info("\n" + "=" * 70)
    logger.info("æ­¥éª¤ 3/5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š")
    logger.info("=" * 70)
    logger.info(f"æŠ¥å‘Šä¸»é¢˜: {query}")
    logger.info(f"è¾“å…¥æŠ¥å‘Šæ•°é‡: {len(reports)}")

    try:
        from ReportEngine.agent import ReportAgent

        # åˆå§‹åŒ–Report Agent
        logger.info("æ­£åœ¨åˆå§‹åŒ– Report Engine...")
        agent = ReportAgent(config=agent_config)

        # å®šä¹‰æµå¼äº‹ä»¶å¤„ç†å™¨
        def stream_handler(event_type: str, payload: Dict[str, Any]):
            """å¤„ç†Report Engineçš„æµå¼äº‹ä»¶"""
            if event_type == "stage":
                stage = payload.get("stage", "")
                if stage == "agent_start":
                    logger.info(f"å¼€å§‹ç”ŸæˆæŠ¥å‘Š: {payload.get('report_id', '')}")
                elif stage == "template_selected":
                    logger.info(f"âœ“ å·²é€‰æ‹©æ¨¡æ¿: {payload.get('template', '')}")
                elif stage == "template_sliced":
                    logger.info(f"âœ“ æ¨¡æ¿è§£æå®Œæˆï¼Œå…± {payload.get('section_count', 0)} ä¸ªç« èŠ‚")
                elif stage == "layout_designed":
                    logger.info(f"âœ“ æ–‡æ¡£å¸ƒå±€è®¾è®¡å®Œæˆ")
                    logger.info(f"  æ ‡é¢˜: {payload.get('title', '')}")
                elif stage == "word_plan_ready":
                    logger.info(f"âœ“ ç¯‡å¹…è§„åˆ’å®Œæˆï¼Œç›®æ ‡ç« èŠ‚æ•°: {payload.get('chapter_targets', 0)}")
                elif stage == "chapters_compiled":
                    logger.info(f"âœ“ ç« èŠ‚ç”Ÿæˆå®Œæˆï¼Œå…± {payload.get('chapter_count', 0)} ä¸ªç« èŠ‚")
                elif stage == "html_rendered":
                    logger.info(f"âœ“ HTML æ¸²æŸ“å®Œæˆ")
                elif stage == "report_saved":
                    logger.info(f"âœ“ æŠ¥å‘Šå·²ä¿å­˜")
            elif event_type == "chapter_status":
                chapter_id = payload.get("chapterId", "")
                title = payload.get("title", "")
                status = payload.get("status", "")
                if status == "generating":
                    logger.info(f"  æ­£åœ¨ç”Ÿæˆç« èŠ‚: {title}")
                elif status == "completed":
                    attempt = payload.get("attempt", 1)
                    warning = payload.get("warning", "")
                    if warning:
                        logger.warning(f"  âœ“ ç« èŠ‚å®Œæˆ: {title} (ç¬¬ {attempt} æ¬¡å°è¯•ï¼Œ{payload.get('warningMessage', '')})")
                    else:
                        logger.success(f"  âœ“ ç« èŠ‚å®Œæˆ: {title}")
            elif event_type == "error":
                logger.error(f"é”™è¯¯: {payload.get('message', '')}")

        # ç”ŸæˆæŠ¥å‘Š
        logger.info("å¼€å§‹ç”ŸæˆæŠ¥å‘Šï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´...")
        result = agent.generate_report(
            query=query,
            reports=reports,
            forum_logs="",  # ä¸ä½¿ç”¨è®ºå›æ—¥å¿—
            custom_template="",  # ä½¿ç”¨è‡ªåŠ¨æ¨¡æ¿é€‰æ‹©
            save_report=True,  # è‡ªåŠ¨ä¿å­˜æŠ¥å‘Š
            stream_handler=stream_handler
        )

        logger.success("âœ“ æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
        return result

    except Exception as e:
        logger.exception(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        sys.exit(1)


def save_pdf(document_ir_path: str, query: str) -> Optional[str]:
    """
    ä»IRæ–‡ä»¶ç”Ÿæˆå¹¶ä¿å­˜PDF
    """
    logger.info("\næ­£åœ¨ç”Ÿæˆ PDF æ–‡ä»¶...")

    try:
        # è¯»å–IRæ•°æ®
        with open(document_ir_path, "r", encoding="utf-8") as f:
            document_ir = json.load(f)

        # åˆ›å»ºPDFæ¸²æŸ“å™¨
        from ReportEngine.renderers import PDFRenderer
        renderer = PDFRenderer()

        # å‡†å¤‡è¾“å‡ºè·¯å¾„
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        query_safe = "".join(
            c for c in query if c.isalnum() or c in (" ", "-", "_")
        ).rstrip()
        query_safe = query_safe.replace(" ", "_")[:30] or "report"

        pdf_dir = Path("final_reports") / "pdf"
        pdf_dir.mkdir(parents=True, exist_ok=True)

        pdf_filename = f"final_report_{query_safe}_{timestamp}.pdf"
        pdf_path = pdf_dir / pdf_filename

        # ä½¿ç”¨ render_to_pdf æ–¹æ³•ç›´æ¥ç”ŸæˆPDFæ–‡ä»¶ï¼Œä¼ å…¥ IR æ–‡ä»¶è·¯å¾„ç”¨äºä¿®å¤åä¿å­˜
        logger.info(f"å¼€å§‹æ¸²æŸ“PDF: {pdf_path}")
        result_path = renderer.render_to_pdf(
            document_ir,
            pdf_path,
            optimize_layout=True,
            ir_file_path=document_ir_path
        )

        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
        file_size = result_path.stat().st_size
        size_mb = file_size / (1024 * 1024)
        logger.success(f"âœ“ PDF å·²ä¿å­˜: {pdf_path}")
        logger.info(f"  æ–‡ä»¶å¤§å°: {size_mb:.2f} MB")

        return str(result_path)

    except Exception as e:
        logger.exception(f"âŒ PDF ç”Ÿæˆå¤±è´¥: {e}")
        return None


def save_markdown(document_ir_path: str, query: str) -> Optional[str]:
    """
    ä»IRæ–‡ä»¶ç”Ÿæˆå¹¶ä¿å­˜Markdown
    """
    logger.info("\næ­£åœ¨ç”Ÿæˆ Markdown æ–‡ä»¶...")

    try:
        with open(document_ir_path, "r", encoding="utf-8") as f:
            document_ir = json.load(f)

        from ReportEngine.renderers import MarkdownRenderer
        renderer = MarkdownRenderer()
        # ä¼ å…¥ IR æ–‡ä»¶è·¯å¾„ç”¨äºä¿®å¤åä¿å­˜
        markdown_content = renderer.render(document_ir, ir_file_path=document_ir_path)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        query_safe = "".join(
            c for c in query if c.isalnum() or c in (" ", "-", "_")
        ).rstrip()
        query_safe = query_safe.replace(" ", "_")[:30] or "report"

        md_dir = Path("final_reports") / "md"
        md_dir.mkdir(parents=True, exist_ok=True)

        md_filename = f"final_report_{query_safe}_{timestamp}.md"
        md_path = md_dir / md_filename

        md_path.write_text(markdown_content, encoding="utf-8")

        file_size_kb = md_path.stat().st_size / 1024
        logger.success(f"âœ“ Markdown å·²ä¿å­˜: {md_path}")
        logger.info(f"  æ–‡ä»¶å¤§å°: {file_size_kb:.1f} KB")

        return str(md_path)

    except Exception as e:
        logger.exception(f"âŒ Markdown ç”Ÿæˆå¤±è´¥: {e}")
        return None


def save_to_supabase(title: str, content: str):
    """
    å°†æŠ¥å‘Šä¿å­˜åˆ° Supabase æ•°æ®åº“ (ä½¿ç”¨ Requests API)
    """
    logger.info("\n" + "=" * 70)
    logger.info("æ­¥éª¤ 5/5: ä¿å­˜åˆ° Supabase æ•°æ®åº“")
    logger.info("=" * 70)
    
    # è·å–ç¯å¢ƒå˜é‡
    url = os.environ.get("SUPABASE_URL") or os.environ.get("VITE_SUPABASE_URL")
    key = os.environ.get("SUPABASE_KEY") or os.environ.get("VITE_SUPABASE_KEY")
    
    if not url or not key:
        logger.error("âŒ ç¼ºå°‘ Supabase é…ç½® (SUPABASE_URL æˆ– SUPABASE_KEY)")
        return
        
    try:
        logger.info("æ­£åœ¨è¿æ¥ Supabase (REST API)...")
        
        # æ„é€  REST API URL
        # å‡è®¾ URL æ ¼å¼ä¸º https://xyz.supabase.co
        api_url = f"{url}/rest/v1/market_news"
        
        headers = {
            "apikey": key,
            "Authorization": f"Bearer {key}",
            "Content-Type": "application/json",
            "Prefer": "return=minimal"
        }
        
        data = {
            "title": title,
            "content": content,
            "created_at": datetime.now().isoformat()
        }
        
        # æ’å…¥æ•°æ®
        logger.info(f"æ­£åœ¨æ’å…¥æ•°æ®: {title}")
        response = requests.post(api_url, headers=headers, json=data)
        
        if response.status_code in [200, 201]:
            logger.success(f"âœ“ æ•°æ®å·²æˆåŠŸå­˜å…¥ market_news è¡¨")
        else:
            logger.error(f"âŒ ä¿å­˜å¤±è´¥: {response.status_code} - {response.text}")
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜åˆ° Supabase å¤±è´¥: {e}")
def parse_bool_arg(value: str) -> bool:
    """å°†å­—ç¬¦ä¸²è§£æä¸ºå¸ƒå°”å€¼ï¼Œç”¨äºå‘½ä»¤è¡Œå‚æ•°"""
    true_values = {"true", "1", "yes", "y", "on"}
    false_values = {"false", "0", "no", "n", "off"}

    value_lower = value.lower()
    if value_lower in true_values:
        return True
    if value_lower in false_values:
        return False
    raise argparse.ArgumentTypeError("GRAPHRAG_ENABLED ä»…æ¥å— true/false")


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="Report Engine å‘½ä»¤è¡Œç‰ˆæœ¬ - æ— éœ€å‰ç«¯çš„æŠ¥å‘Šç”Ÿæˆå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python report_engine_only.py
  python report_engine_only.py --query "åœŸæœ¨å·¥ç¨‹è¡Œä¸šåˆ†æ"
  python report_engine_only.py --skip-pdf --verbose
  python report_engine_only.py --auto
        """
    )

    parser.add_argument(
        "--query",
        type=str,
        default=None,
        help="æŒ‡å®šæŠ¥å‘Šä¸»é¢˜ï¼ˆé»˜è®¤ä»æ–‡ä»¶åè‡ªåŠ¨æå–ï¼‰"
    )

    parser.add_argument(
        "--skip-pdf",
        action="store_true",
        help="è·³è¿‡PDFç”Ÿæˆï¼ˆå³ä½¿ç³»ç»Ÿæ”¯æŒï¼‰"
    )

    parser.add_argument(
        "--skip-markdown",
        action="store_true",
        help="è·³è¿‡Markdownç”Ÿæˆ"
    )

    parser.add_argument(
        "--verbose",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—ä¿¡æ¯"
    )
    
    parser.add_argument(
        "--auto",
        action="store_true",
        help="è‡ªåŠ¨ç¡®è®¤æ‰€æœ‰æç¤ºï¼Œç”¨äºè‡ªåŠ¨åŒ–è„šæœ¬"
    )

    parser.add_argument(
        "--graphrag-enabled",
        type=parse_bool_arg,
        default=None,
        help="æ˜¯å¦å¼€å¯GraphRAGï¼Œé»˜è®¤éµå¾ª .envï¼ˆæœªè®¾ç½®åˆ™å…³é—­ï¼‰"
    )

    parser.add_argument(
        "--graphrag-max-queries",
        type=int,
        default=None,
        help="GraphRAG æ¯ç« èŠ‚æœ€å¤§æŸ¥è¯¢æ¬¡æ•°ï¼ˆé»˜è®¤éµå¾ª .envï¼Œä¸”ä»…åœ¨å¼€å¯æ—¶ç”Ÿæ•ˆï¼‰"
    )

    return parser.parse_args()


def build_agent_config(args) -> Settings:
    """åŸºäº .env é…ç½®å¹¶èåˆå‘½ä»¤è¡Œè¦†ç›–é¡¹ç”Ÿæˆæœ€ç»ˆé…ç½®"""
    # å¼ºåˆ¶é‡æ–°åŠ è½½é…ç½®ï¼Œç¡®ä¿è·å–æœ€æ–°çš„ç¯å¢ƒå˜é‡
    try:
        current_settings = Settings()
    except Exception as e:
        logger.warning(f"é‡æ–°åŠ è½½é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
        current_settings = global_settings

    config_overrides: Dict[str, Any] = {}

    # è‡ªåŠ¨é€‚é… DeepSeek (å¦‚æœç”¨æˆ·åªé…äº† Key æ²¡æ”¹ URL)
    # å‡è®¾ DeepSeek Key ä»¥ sk- å¼€å¤´ï¼Œä¸”å½“å‰ Base URL æ˜¯é»˜è®¤çš„ aihubmix
    api_key = current_settings.REPORT_ENGINE_API_KEY
    base_url = current_settings.REPORT_ENGINE_BASE_URL
    
    if api_key and api_key.startswith("sk-") and "aihubmix" in (base_url or ""):
        logger.info("ğŸ”§ æ£€æµ‹åˆ° DeepSeek é£æ ¼ API Keyï¼Œè‡ªåŠ¨åˆ‡æ¢è‡³ DeepSeek å®˜æ–¹èŠ‚ç‚¹")
        config_overrides["REPORT_ENGINE_BASE_URL"] = "https://api.deepseek.com"
        config_overrides["REPORT_ENGINE_MODEL_NAME"] = "deepseek-chat"

    if args.graphrag_enabled is not None:
        config_overrides["GRAPHRAG_ENABLED"] = args.graphrag_enabled
    if args.graphrag_max_queries is not None:
        if args.graphrag_max_queries <= 0:
            logger.warning("GRAPHRAG_MAX_QUERIES å¿…é¡»å¤§äº 0ï¼Œæœ¬æ¬¡å°†ç»§ç»­ä½¿ç”¨ .env/é»˜è®¤å€¼")
        else:
            config_overrides["GRAPHRAG_MAX_QUERIES"] = args.graphrag_max_queries

    if not config_overrides:
        return current_settings

    return current_settings.model_copy(update=config_overrides)


def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½ .env (å¦‚æœ python-dotenv å·²å®‰è£…ï¼Œé€šå¸¸åœ¨ config.py ä¸­åŠ è½½ï¼Œè¿™é‡Œæ˜¾å¼åŠ è½½ä¸€ä¸‹ä»¥é˜²ä¸‡ä¸€)
    try:
        from dotenv import load_dotenv
        load_dotenv()
    except ImportError:
        pass

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()

    # è®¾ç½®æ—¥å¿—
    setup_logger(verbose=args.verbose)

    logger.info("\n")
    logger.info("â•”" + "â•" * 68 + "â•—")
    logger.info("â•‘" + " " * 20 + "Report Engine å‘½ä»¤è¡Œç‰ˆæœ¬" + " " * 24 + "â•‘")
    logger.info("â•š" + "â•" * 68 + "â•")
    logger.info("\n")

    # åˆå¹¶ GraphRAG ç›¸å…³é…ç½®ï¼ˆå‘½ä»¤è¡Œ > .env > é»˜è®¤å…³é—­ï¼‰
    agent_config = build_agent_config(args)
    logger.info(
        f"GraphRAG å¼€å…³: {agent_config.GRAPHRAG_ENABLED} "
        "(ä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œ > .env > é»˜è®¤False)"
    )
    if agent_config.GRAPHRAG_ENABLED:
        logger.info(f"GraphRAG æŸ¥è¯¢ä¸Šé™: {agent_config.GRAPHRAG_MAX_QUERIES}")

    # æ­¥éª¤ 1: æ£€æŸ¥ä¾èµ–
    pdf_available, _ = check_dependencies()
    markdown_enabled = not args.skip_markdown

    # å¦‚æœç”¨æˆ·æŒ‡å®šè·³è¿‡PDFï¼Œåˆ™ç¦ç”¨PDFç”Ÿæˆ
    if args.skip_pdf:
        logger.info("ç”¨æˆ·æŒ‡å®š --skip-pdfï¼Œå°†è·³è¿‡ PDF ç”Ÿæˆ")
        pdf_available = False

    if not markdown_enabled:
        logger.info("ç”¨æˆ·æŒ‡å®š --skip-markdownï¼Œå°†è·³è¿‡ Markdown ç”Ÿæˆ")

    # æ­¥éª¤ 2: è·å–æœ€æ–°æ–‡ä»¶æˆ–ä½¿ç”¨ Query æ¨¡å¼
    if args.query:
        logger.info(f"æ£€æµ‹åˆ°è‡ªå®šä¹‰ Query: {args.query}")
        logger.info(">> ç‹¬ç«‹æ¨¡å¼: è·³è¿‡æœ¬åœ°æ–‡ä»¶æ‰«æï¼Œå°†ç›´æ¥è°ƒç”¨ AI ç”ŸæˆæŠ¥å‘Š")
        # æ„é€ ä¸€ä¸ªè™šæ‹Ÿçš„ä¸Šä¸‹æ–‡ï¼Œè®© Agent åŸºäº Query å‘æŒ¥
        reports = [f"System Notification: No background documents provided. Please generate a comprehensive market report based on the topic '{args.query}' using your internal knowledgebase."]
        query = args.query
    else:
        latest_files = get_latest_engine_reports()

        # ç¡®è®¤æ–‡ä»¶é€‰æ‹©
        if not confirm_file_selection(latest_files, auto_confirm=args.auto):
            logger.info("\nç¨‹åºå·²é€€å‡º")
            sys.exit(0)

        # åŠ è½½æŠ¥å‘Šå†…å®¹
        reports = load_engine_reports(latest_files)

        if not reports:
            logger.error("âŒ æœªèƒ½åŠ è½½ä»»ä½•æŠ¥å‘Šå†…å®¹")
            sys.exit(1)

        # æå–æˆ–ä½¿ç”¨æŒ‡å®šçš„æŸ¥è¯¢ä¸»é¢˜
        query = extract_query_from_reports(latest_files)

    logger.info(f"ä½¿ç”¨æŠ¥å‘Šä¸»é¢˜: {query}")

    # æ­¥éª¤ 3: ç”ŸæˆæŠ¥å‘Š
    result = generate_report(reports, query, pdf_available, agent_config)

    # æ­¥éª¤ 4: ä¿å­˜æ–‡ä»¶
    logger.info("\n" + "=" * 70)
    logger.info("æ­¥éª¤ 4/5: ä¿å­˜ç”Ÿæˆçš„æ–‡ä»¶")
    logger.info("=" * 70)

    # HTML å·²ç»åœ¨ generate_report ä¸­è‡ªåŠ¨ä¿å­˜
    html_path = result.get("report_filepath", "")
    ir_path = result.get("ir_filepath", "")
    pdf_path = None
    markdown_path = None
    markdown_content = None # ç”¨äºå­˜å‚¨åˆ°æ•°æ®åº“

    if html_path:
        logger.success(f"âœ“ HTML å·²ä¿å­˜: {result.get('report_relative_path', html_path)}")

    # å¦‚æœæœ‰PDFä¾èµ–ï¼Œç”Ÿæˆå¹¶ä¿å­˜PDF
    if pdf_available:
        if ir_path and os.path.exists(ir_path):
            pdf_path = save_pdf(ir_path, query)
        else:
            logger.warning("âš  æœªæ‰¾åˆ° IR æ–‡ä»¶ï¼Œæ— æ³•ç”Ÿæˆ PDF")
    else:
        logger.info("âš  è·³è¿‡ PDF ç”Ÿæˆï¼ˆç¼ºå°‘ç³»ç»Ÿä¾èµ–æˆ–ç”¨æˆ·æŒ‡å®šè·³è¿‡ï¼‰")

    # ç”Ÿæˆå¹¶ä¿å­˜Markdownï¼ˆåœ¨PDFä¹‹åï¼‰
    if markdown_enabled:
        if ir_path and os.path.exists(ir_path):
            markdown_path = save_markdown(ir_path, query)
            # è¯»å–Markdownå†…å®¹ç”¨äºå…¥åº“
            if markdown_path and os.path.exists(markdown_path):
                try:
                    with open(markdown_path, "r", encoding="utf-8") as f:
                        markdown_content = f.read()
                except Exception as e:
                    logger.error(f"è¯»å– Markdown æ–‡ä»¶å¤±è´¥: {e}")
        else:
            logger.warning("âš  æœªæ‰¾åˆ° IR æ–‡ä»¶ï¼Œæ— æ³•ç”Ÿæˆ Markdown")
    else:
        logger.info("âš  è·³è¿‡ Markdown ç”Ÿæˆï¼ˆç”¨æˆ·æŒ‡å®šï¼‰")

    # æ­¥éª¤ 5: å…¥åº“
    if markdown_content:
        save_to_supabase(title=f"åˆ†ææŠ¥å‘Š: {query}", content=markdown_content)
    else:
        logger.warning("âš  æ²¡æœ‰ Markdown å†…å®¹ï¼Œè·³è¿‡æ•°æ®åº“å­˜å‚¨")

    # æ€»ç»“
    logger.info("\n" + "=" * 70)
    logger.success("âœ“ æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
    logger.info("=" * 70)
    logger.info(f"æŠ¥å‘Š ID: {result.get('report_id', 'N/A')}")
    logger.info(f"HTML æ–‡ä»¶: {result.get('report_relative_path', 'N/A')}")
    if pdf_available:
        if pdf_path:
            logger.info(f"PDF æ–‡ä»¶: {os.path.relpath(pdf_path, os.getcwd())}")
        else:
            logger.info("PDF æ–‡ä»¶: ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    else:
        logger.info("PDF æ–‡ä»¶: å·²è·³è¿‡")
    if markdown_enabled:
        if markdown_path:
            logger.info(f"Markdown æ–‡ä»¶: {os.path.relpath(markdown_path, os.getcwd())}")
        else:
            logger.info("Markdown æ–‡ä»¶: ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    else:
        logger.info("Markdown æ–‡ä»¶: å·²è·³è¿‡")
    logger.info("=" * 70)
    logger.info("\nç¨‹åºç»“æŸ")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.warning("\n\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
        sys.exit(0)
    except Exception as e:
        logger.exception(f"\nç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        sys.exit(1)
